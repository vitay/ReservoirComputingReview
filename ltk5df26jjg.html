<h1 data-label="761552" class="ltx_title_section"> Introduction</h1><div></div><h2 data-label="422720" class="ltx_title_subsection">What is reservoir computing?</h2><div></div><ul><li>Echo-state networks&nbsp;<cite class="ltx_cite raw v1">\cite{Jaeger_2007}</cite>&nbsp; / The “echo state” approach to analysing and training recurrent neural networks – with an Erratum note, H. Jaeger 2010 (<a href="https://www.researchgate.net/profile/Herbert_Jaeger3/publication/215385037_The_echo_state_approach_to_analysing_and_training_recurrent_neural_networks-with_an_erratum_note'/links/566a003508ae62b05f027be3/The-echo-state-approach-to-analysing-and-training-recurrent-neural-networks-with-an-erratum-note.pdf">https://www.researchgate.net/profile/Herbert_Jaeger3/publication/215385037_The_echo_state_approach_to_analysing_and_training_recurrent_neural_networks-with_an_erratum_note'/links/566a003508ae62b05f027be3/The-echo-state-approach-to-analysing-and-training-recurrent-neural-networks-with-an-erratum-note.pdf</a>)</li><li>Liquid-state machines <cite class="ltx_cite raw v1">\cite{Maass_2002}</cite></li></ul><div></div><h2 data-label="923846" class="ltx_title_subsection">Existing reviews on reservoir computing</h2><div></div><ul><li>Future directions for ESNs <cite class="ltx_cite raw v1">\cite{Jaeger}</cite></li><li>Special issue on echo state networks and liquid state machines <cite class="ltx_cite raw v1">\cite{Jaeger_2007a}</cite></li><li>Reservoir computing approaches to recurrent neural network training <cite class="ltx_cite raw v1">\cite{Luko_evi_ius_2009}</cite></li><li>Reservoir computing trends <cite class="ltx_cite raw v1">\cite{Luko_evi_ius_2012}</cite></li><li>Liquid state machines: Motivation, theory and applications <cite class="ltx_cite raw v1">\cite{Maass_2011}</cite></li></ul><div></div><h2 data-label="389123" class="ltx_title_subsection">Motivation for and purpose of this review</h2><div></div><h3 data-label="211185" class="ltx_title_subsubsection">1.3.1 Motivation</h3><div>Wide range of studies that bring together RC principles and neuroscientific questions and vice versa.</div><div>What is the collective picture so far that those studies provide of brain function from the perspective of reservoir computing?</div><ul><li>which aspects of neural signalling dynamics can be addressed by RC?</li><li>which aspects of brain function can be modeled via RC?</li><li>what might be the neural substrates of RC principles/mechanisms?</li></ul><div></div><h3 data-label="907478" class="ltx_title_subsubsection">1.3.2 Goal</h3><div>Developing an explicit account of how the brain implements and employs reservoir computing principles</div><div></div><h1 data-label="748924" class="ltx_title_section">2 Reservoir Computing as a Model for Sequence Learning in the Brain</h1><div></div><h2 data-label="877560" class="ltx_title_subsection">2.1 Supervised learning (standard read-out training etc.)</h2><h2 data-label="600188" class="ltx_title_subsection">2.2 Unsupervised learning (self-organization, plasticity mechanisms)</h2><h2 data-label="893657" class="ltx_title_subsection">2.3 Weakly-supervised learning (reinforcement learning paradigms)</h2><div></div><h1>3 Modeling Brain Phenomena via Reservoir Computing</h1>