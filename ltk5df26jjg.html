<h1 data-label="761552" class="ltx_title_section"> Introduction</h1><div></div><h2 data-label="422720" class="ltx_title_subsection">What is reservoir computing?</h2><div></div><ul><li>Echo-state networks&nbsp;<cite class="ltx_cite raw v1">\cite{Jaeger_2007}</cite>&nbsp; / The “echo state” approach to analysing and training recurrent neural networks – with an Erratum note, H. Jaeger 2010 (<a href="https://www.researchgate.net/profile/Herbert_Jaeger3/publication/215385037_The_echo_state_approach_to_analysing_and_training_recurrent_neural_networks-with_an_erratum_note'/links/566a003508ae62b05f027be3/The-echo-state-approach-to-analysing-and-training-recurrent-neural-networks-with-an-erratum-note.pdf">https://www.researchgate.net/profile/Herbert_Jaeger3/publication/215385037_The_echo_state_approach_to_analysing_and_training_recurrent_neural_networks-with_an_erratum_note'/links/566a003508ae62b05f027be3/The-echo-state-approach-to-analysing-and-training-recurrent-neural-networks-with-an-erratum-note.pdf</a>)</li><li>Liquid-state machines <cite class="ltx_cite raw v1">\cite{Maass_2002}</cite></li><li>Lay out difference to deep learning, where deep learning can be a proper tool to model brain networks and where current deep learning architectures have a deficiency in modeling brain structures/phenomena&nbsp;</li></ul><h2 data-label="331158" class="ltx_title_subsection">Definitions of RC:</h2><div></div><ul><li><cite class="ltx_cite raw v1">\cite{Jaeger}</cite>: RC is a RNN learning architecture defined by 1)&nbsp;a large, randomly connected, recurrent “reservoir”&nbsp;network&nbsp;that is passively excited by the task's input signal, and 2)&nbsp;trainable readout neurons that combine the desired output from the excited reservoir state.</li><li><cite class="ltx_cite raw v1">\cite{Luko_evi_ius_2009}</cite>:&nbsp;RC is a RNN learning architecture defined by 1)&nbsp;a  recurrent “reservoir”&nbsp;network&nbsp;that is passively excited by the task's input signal, and 2) non-recurrent readout neurons, with 1) and 2) using different learning methods.</li><li><cite class="ltx_cite raw v1">\cite{Luko_evi_ius_2012}</cite>:&nbsp;Reservoir Computing (RC) is a paradigm of understanding and training Recurrent Neural Networks (RNNs) based on treating the recurrent part (the&nbsp;<i>reservoir</i>) differently than the readouts from it.</li><li><cite class="ltx_cite raw v1">\cite{Maass_2011}</cite>&nbsp;RC is a learning architecture defined by&nbsp;1)&nbsp;a large, randomly connected, recurrent “reservoir”&nbsp;network&nbsp;that is passively excited by the task's input signal, and 2)&nbsp;trainable readout neurons that linearly combine the desired output from the excited reservoir state.</li><li>Additional criteria:</li><li></li></ul><div></div>